# ML-Tutorial
This repository contains Colab Notebooks with different models for Supervised and Unsupervised Machine Learning tasks.

## Classification Models
The *Classification-[MAGIC-GAMMA-dataset].ipynb* Colab Notebook consists of Classification Models like K-Nearest Neighbours(KNN), Naive Bayes(NB), Logistic Regression, Support Vector Classifier(SVC), and a Neural Network Classifier.

### Dataset
The dataset used is the "MAGIC Gamma Telescope" dataset (https://archive.ics.uci.edu/dataset/159/magic+gamma+telescope) from UCI Machine Learning Repository. It has 10 features and 19020 instances of the real data type. It is used to classify photons into binary classes: Gamma('g') and Hadron('h'). The data provided is clean and does not have any missing values.

The dataset was generated by a Monte Carlo program, Corsika, described in: D. Heck et al., CORSIKA, A Monte Carlo code to simulate extensive air showers, Forschungszentrum Karlsruhe FZKA 6019 (1998). (http://rexa.info/paper?id=ac6e674e9af20979b23d3ed4521f1570765e8d68)

### Data Preprocessing
The data is clean but it is missing column headers. Column names are added to the imported CSV. There are two classes:- 'g' and 'h' which are converted into 1's and 0's respectively for more efficiency. For a better understanding of the dataset, multiple histograms are plotted for the probability of a photon being either a 'gamma' (blue) or a 'hadron' (red), against each feature. The most significant distinction between the two is for the feature 'fAlpha'.

The values of feature vectors have a large range, which is why a Standard Scaler is used for Normalization/Standardization. This helps in an equal comparison of the features, and a more efficient and stable model.

### Train, Test and Validation Split
The entire dataset is randomly split (shuffled then split) into Train, Test and Validation datasets, where the *train* dataset consists of 60% of the data, the *valid* dataset consists of 20% of the data and the *test* dataset consists of the remaining 20% of the data. 

The *train* dataset has an uneven distribution of Gamma's and Hadron's. So, a Random Oversampler is used to increase the number of instances of the weaker class (Hadrons). This is only done for the *train* dataset, and not for the unseen *valid* or *test* dataset.

### Evaluation Metrics
The different models used for classification are compared using the *classification report* which includes metrics like **Accuracy**, **Precision**, **Recall** and **F1 Score**. The Neural Network Classifier which was trained on different combinations of number of nodes, dropout, learning rate and batch size had the most Accuracy of 0.86. Graphs for Accuracy and Loss were plotted for Neural Network Classifier where loss is evaluated using Binary Cross Entropy Loss. While the Naive Bayes model performed most poorly with an Accuracy of only 0.73, the Support Vector Classifier model performed well with an accuracy of 0.85. The K-Nearest Neighbours Classifier and the Logistic Regression model performed moderately well with an Accuracy of 0.81 and 0.79 respectively.

## Regression Models
The *Regression-[Seoul-bike-dataset].ipynb* Colab Notebook consists of Regression models like Linear Regression and Regression using Neural Networks.

### Dataset
The dataset used is the "Seoul Bike Sharing Demand" dataset ([https://archive.ics.uci.edu/dataset/560/seoul+bike+sharing+demand]) from UCI Machine Learning Repository. The dataset contains weather information (Temperature, Humidity, Windspeed, Visibility, Dewpoint, Solar radiation, Snowfall, Rainfall), the number of bikes rented per hour and date information. It has 13 features and 8760 instances that are clean and of real or integer data type. 
